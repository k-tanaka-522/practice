# AI-MLçµ±åˆç·¨

## æ¦‚è¦

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€AWS Bedrockã‚’ä¸­å¿ƒã¨ã—ãŸAI/MLã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ±åˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€RAGã‚·ã‚¹ãƒ†ãƒ ã€ç”»åƒç”Ÿæˆãªã©ã®å®Ÿç”¨çš„ãªAIæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚Claudeã€GPTã€Stable Diffusionç­‰ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸæœ¬æ ¼çš„ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã‚’å­¦ç¿’ã—ã¾ã™ã€‚

## å­¦ç¿’ç›®æ¨™

- ğŸ¤– **Amazon Bedrock**: åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒç”Ÿæˆ
- ğŸ’¬ **ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ**: Claude/GPTã‚’ä½¿ã£ãŸå¯¾è©±AI
- ğŸ” **RAGã‚·ã‚¹ãƒ†ãƒ **: æ¤œç´¢æ‹¡å¼µç”Ÿæˆã«ã‚ˆã‚‹çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ´»ç”¨
- ğŸ¨ **ç”»åƒç”Ÿæˆ**: Stable Diffusionç­‰ã«ã‚ˆã‚‹ç”»åƒAI
- ğŸš€ **MLOps**: ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã€ç›£è¦–

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Services Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Bedrock   â”‚  â”‚ SageMaker   â”‚  â”‚  Textract   â”‚  â”‚ Polly   â”‚ â”‚
â”‚  â”‚ Foundation  â”‚  â”‚   Models    â”‚  â”‚   OCR/NLP   â”‚  â”‚  TTS    â”‚ â”‚
â”‚  â”‚   Models    â”‚  â”‚             â”‚  â”‚             â”‚  â”‚         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Lambda    â”‚  â”‚ API Gateway â”‚  â”‚ EventBridge â”‚  â”‚   SQS   â”‚ â”‚
â”‚  â”‚ AI Functionsâ”‚  â”‚ AI Endpointsâ”‚  â”‚   Events    â”‚  â”‚ Queues  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Storage Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     S3      â”‚  â”‚  DynamoDB   â”‚  â”‚ OpenSearch  â”‚  â”‚  RDS    â”‚ â”‚
â”‚  â”‚ Documents   â”‚  â”‚ Chat Historyâ”‚  â”‚ Vector DB   â”‚  â”‚Knowledgeâ”‚ â”‚
â”‚  â”‚  & Media    â”‚  â”‚             â”‚  â”‚             â”‚  â”‚  Base   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Frontend Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   React     â”‚  â”‚   Amplify   â”‚  â”‚  CloudFront â”‚  â”‚  Route  â”‚ â”‚
â”‚  â”‚   Chat UI   â”‚  â”‚   Hosting   â”‚  â”‚     CDN     â”‚  â”‚   53    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å­¦ç¿’ãƒ‘ã‚¹

### 5.1 BedrockåŸºç¤
- **5.1.1** Bedrockã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
- **5.1.2** ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Ÿè£…

### 5.2 AIæ©Ÿèƒ½å®Ÿè£…
- **5.2.1** ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½œæˆ
- **5.2.2** RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
- **5.2.3** ç”»åƒç”Ÿæˆæ©Ÿèƒ½

### 5.3 é«˜åº¦ãªMLOpsï¼ˆæ‹¡å¼µï¼‰
- **5.3.1** ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨æœ€é©åŒ–
- **5.3.2** A/Bãƒ†ã‚¹ãƒˆã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å‰ææ¡ä»¶

```bash
# AWS CLIç¢ºèª
aws --version

# Pythonç’°å¢ƒç¢ºèªï¼ˆAI/MLç”¨ï¼‰
python3 --version
pip3 install boto3 langchain

# Node.jsç¢ºèªï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰
node --version
npm install @aws-sdk/client-bedrock-runtime
```

### Bedrockãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ç”³è«‹

```bash
# ä½¿ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
aws bedrock list-foundation-models --region us-east-1

# ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ç”³è«‹ï¼ˆAWS ConsoleçµŒç”±ï¼‰
echo "https://console.aws.amazon.com/bedrock/ ã§ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç”³è«‹ã—ã¦ãã ã•ã„"
echo "ä¸»è¦ãƒ¢ãƒ‡ãƒ«: Claude, Titan, Jurassic, Command, Llama"
```

### å…¨ä½“ãƒ‡ãƒ—ãƒ­ã‚¤

```bash
# AI-MLçµ±åˆåŸºç›¤ã®ä¸€æ‹¬ãƒ‡ãƒ—ãƒ­ã‚¤
./scripts/deploy-all-infrastructure.sh deploy-ai-ml

# æ®µéšçš„ãƒ‡ãƒ—ãƒ­ã‚¤
./scripts/deploy-ai-ml.sh deploy-bedrock
./scripts/deploy-ai-ml.sh deploy-chatbot
./scripts/deploy-ai-ml.sh deploy-rag
./scripts/deploy-ai-ml.sh deploy-image-gen
```

## å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è©³ç´°

### ğŸ¤– 5.1.1 Bedrockã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

**å­¦ç¿’å†…å®¹:**
- Amazon Bedrockã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦
- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã¨ç‰¹å¾´
- ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
- ã‚³ã‚¹ãƒˆæœ€é©åŒ–æˆ¦ç•¥

**å®Ÿè£…å†…å®¹:**
- Bedrock IAMãƒ­ãƒ¼ãƒ«è¨­å®š
- ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç®¡ç†
- VPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®š
- ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«çµ±åˆæº–å‚™

**ä¸»è¦æŠ€è¡“:**
- Amazon Bedrock
- IAM Policyç®¡ç†
- VPC Endpoints
- CloudWatchç›£è¦–

### ğŸ“ 5.1.2 ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Ÿè£…

**å­¦ç¿’å†…å®¹:**
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAPIçµ±åˆ
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
- å“è³ªè©•ä¾¡ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

**å®Ÿè£…å†…å®¹:**
- Lambdaé–¢æ•°ã§ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
- API Gatewayçµ±åˆ
- ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
- æœ‰å®³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿

**ä¸»è¦æŠ€è¡“:**
- Bedrock Text Modelsï¼ˆClaude, Titanï¼‰
- Lambda Streaming
- ElastiCache
- Content Moderation

### ğŸ’¬ 5.2.1 ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½œæˆ

**å­¦ç¿’å†…å®¹:**
- å¯¾è©±AIè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
- å¤šè¨€èªå¯¾å¿œ
- æ„Ÿæƒ…åˆ†æçµ±åˆ

**å®Ÿè£…å†…å®¹:**
- React ãƒãƒ£ãƒƒãƒˆUI
- WebSocket ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡
- ä¼šè©±å±¥æ­´ç®¡ç†ï¼ˆDynamoDBï¼‰
- éŸ³å£°å…¥å‡ºåŠ›çµ±åˆ

**ä¸»è¦æŠ€è¡“:**
- Amazon Bedrock (Claude/GPT)
- API Gateway WebSocket
- DynamoDB Conversations
- Amazon Polly/Transcribe

### ğŸ” 5.2.2 RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰

**å­¦ç¿’å†…å®¹:**
- æ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼ˆRAGï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ
- æ–‡æ›¸åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢æœ€é©åŒ–

**å®Ÿè£…å†…å®¹:**
- OpenSearch ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
- æ–‡æ›¸åˆ†å‰²ãƒ»åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
- é¡ä¼¼åº¦æ¤œç´¢ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ä¸»è¦æŠ€è¡“:**
- Amazon OpenSearch Service
- Bedrock Embeddings (Titan)
- S3 Document Store
- Lambda Processing Pipeline

### ğŸ¨ 5.2.3 ç”»åƒç”Ÿæˆæ©Ÿèƒ½

**å­¦ç¿’å†…å®¹:**
- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆ
- ç”»åƒç·¨é›†ã¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
- ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€
- NSFW ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

**å®Ÿè£…å†…å®¹:**
- Stable Diffusionçµ±åˆ
- ç”»åƒã‚®ãƒ£ãƒ©ãƒªãƒ¼ç®¡ç†
- ãƒãƒƒãƒç”Ÿæˆã‚¸ãƒ§ãƒ–
- ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†

**ä¸»è¦æŠ€è¡“:**
- Bedrock Image Models (Stable Diffusion)
- Amazon Rekognition
- S3 Image Storage
- SQS Queue Processing

## ğŸ› ï¸ å®Ÿè£…ä¾‹

### Bedrock Text Generation

```python
import boto3
import json
from typing import Dict, Any

class BedrockTextGenerator:
    def __init__(self, region_name: str = 'us-east-1'):
        self.bedrock = boto3.client('bedrock-runtime', region_name=region_name)
    
    def generate_text(
        self, 
        prompt: str, 
        model_id: str = 'anthropic.claude-3-sonnet-20240229-v1:0',
        max_tokens: int = 1000,
        temperature: float = 0.7
    ) -> Dict[str, Any]:
        """Generate text using Bedrock"""
        
        # Claude 3 format
        if 'claude-3' in model_id:
            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": max_tokens,
                "temperature": temperature,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
        # Titan format
        elif 'titan' in model_id:
            body = {
                "inputText": prompt,
                "textGenerationConfig": {
                    "maxTokenCount": max_tokens,
                    "temperature": temperature
                }
            }
        
        try:
            response = self.bedrock.invoke_model(
                modelId=model_id,
                body=json.dumps(body),
                contentType='application/json'
            )
            
            result = json.loads(response['body'].read())
            
            if 'claude-3' in model_id:
                generated_text = result['content'][0]['text']
            elif 'titan' in model_id:
                generated_text = result['results'][0]['outputText']
            
            return {
                'text': generated_text,
                'model_id': model_id,
                'tokens_used': result.get('usage', {}).get('output_tokens', 0)
            }
            
        except Exception as e:
            return {'error': str(e)}

# ä½¿ç”¨ä¾‹
generator = BedrockTextGenerator()
result = generator.generate_text(
    prompt="AWSã®ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    temperature=0.5
)
print(result['text'])
```

### RAG Implementation

```python
import boto3
import json
from typing import List, Dict
from opensearchpy import OpenSearch, RequestsHttpConnection
from aws_requests_auth.aws_auth import AWSRequestsAuth

class RAGSystem:
    def __init__(self, opensearch_endpoint: str, region: str = 'us-east-1'):
        self.region = region
        self.bedrock = boto3.client('bedrock-runtime', region_name=region)
        
        # OpenSearch client setup
        credentials = boto3.Session().get_credentials()
        awsauth = AWSRequestsAuth(credentials, region, 'es')
        
        self.opensearch = OpenSearch(
            hosts=[{'host': opensearch_endpoint, 'port': 443}],
            http_auth=awsauth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection
        )
    
    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding using Bedrock Titan"""
        body = {
            "inputText": text
        }
        
        response = self.bedrock.invoke_model(
            modelId='amazon.titan-embed-text-v1',
            body=json.dumps(body),
            contentType='application/json'
        )
        
        result = json.loads(response['body'].read())
        return result['embedding']
    
    def search_documents(self, query: str, k: int = 5) -> List[Dict]:
        """Search for relevant documents"""
        query_embedding = self.generate_embedding(query)
        
        search_body = {
            "size": k,
            "query": {
                "knn": {
                    "content_vector": {
                        "vector": query_embedding,
                        "k": k
                    }
                }
            },
            "_source": ["content", "title", "metadata"]
        }
        
        response = self.opensearch.search(
            index="knowledge-base",
            body=search_body
        )
        
        return [hit['_source'] for hit in response['hits']['hits']]
    
    def generate_answer(self, question: str, context: List[Dict]) -> str:
        """Generate answer using retrieved context"""
        context_text = "\n\n".join([doc['content'] for doc in context])
        
        prompt = f"""ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context_text}

è³ªå•: {question}

å›ç­”:"""
        
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 1000,
            "temperature": 0.3,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        }
        
        response = self.bedrock.invoke_model(
            modelId='anthropic.claude-3-sonnet-20240229-v1:0',
            body=json.dumps(body),
            contentType='application/json'
        )
        
        result = json.loads(response['body'].read())
        return result['content'][0]['text']
    
    def answer_question(self, question: str) -> Dict[str, Any]:
        """Main RAG pipeline"""
        # 1. Search for relevant documents
        relevant_docs = self.search_documents(question)
        
        # 2. Generate answer using context
        answer = self.generate_answer(question, relevant_docs)
        
        return {
            'answer': answer,
            'sources': relevant_docs,
            'num_sources': len(relevant_docs)
        }

# ä½¿ç”¨ä¾‹
rag = RAGSystem('your-opensearch-endpoint.region.es.amazonaws.com')
result = rag.answer_question("AWS Lambdaã®æ–™é‡‘ä½“ç³»ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„")
print(result['answer'])
```

### Image Generation

```python
import boto3
import json
import base64
from typing import Dict, Any

class BedrockImageGenerator:
    def __init__(self, region_name: str = 'us-east-1'):
        self.bedrock = boto3.client('bedrock-runtime', region_name=region_name)
        self.s3 = boto3.client('s3')
    
    def generate_image(
        self,
        prompt: str,
        negative_prompt: str = "",
        style: str = "photographic",
        width: int = 1024,
        height: int = 1024,
        cfg_scale: float = 7.0,
        steps: int = 30,
        seed: int = None
    ) -> Dict[str, Any]:
        """Generate image using Stable Diffusion"""
        
        body = {
            "text_prompts": [
                {
                    "text": prompt,
                    "weight": 1.0
                }
            ],
            "cfg_scale": cfg_scale,
            "width": width,
            "height": height,
            "steps": steps,
            "style_preset": style
        }
        
        if negative_prompt:
            body["text_prompts"].append({
                "text": negative_prompt,
                "weight": -1.0
            })
        
        if seed:
            body["seed"] = seed
        
        try:
            response = self.bedrock.invoke_model(
                modelId='stability.stable-diffusion-xl-v1',
                body=json.dumps(body),
                contentType='application/json'
            )
            
            result = json.loads(response['body'].read())
            
            # Get the generated image
            image_data = result['artifacts'][0]['base64']
            
            return {
                'image_base64': image_data,
                'seed': result['artifacts'][0].get('seed'),
                'finish_reason': result['artifacts'][0].get('finishReason')
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def save_image_to_s3(
        self, 
        image_base64: str, 
        bucket_name: str, 
        key: str
    ) -> str:
        """Save generated image to S3"""
        image_bytes = base64.b64decode(image_base64)
        
        self.s3.put_object(
            Bucket=bucket_name,
            Key=key,
            Body=image_bytes,
            ContentType='image/png'
        )
        
        return f"s3://{bucket_name}/{key}"

# ä½¿ç”¨ä¾‹
generator = BedrockImageGenerator()
result = generator.generate_image(
    prompt="A beautiful sunset over Mount Fuji, digital art style",
    negative_prompt="blurry, low quality",
    style="digital-art"
)

if 'image_base64' in result:
    s3_url = generator.save_image_to_s3(
        result['image_base64'],
        'my-ai-images-bucket',
        f'generated/{datetime.now().isoformat()}.png'
    )
    print(f"Image saved to: {s3_url}")
```

## ğŸ“Š ã‚³ã‚¹ãƒˆæœ€é©åŒ–

### Bedrockä½¿ç”¨é‡ç›£è¦–

```python
import boto3
from datetime import datetime, timedelta

def monitor_bedrock_costs():
    ce = boto3.client('ce')
    
    # éå»30æ—¥ã®Bedrockä½¿ç”¨é‡
    response = ce.get_cost_and_usage(
        TimePeriod={
            'Start': (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'),
            'End': datetime.now().strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['BlendedCost'],
        GroupBy=[
            {
                'Type': 'DIMENSION',
                'Key': 'SERVICE'
            }
        ],
        Filter={
            'Dimensions': {
                'Key': 'SERVICE',
                'Values': ['Amazon Bedrock']
            }
        }
    )
    
    total_cost = 0
    for day in response['ResultsByTime']:
        day_cost = float(day['Total']['BlendedCost']['Amount'])
        total_cost += day_cost
        print(f"{day['TimePeriod']['Start']}: ${day_cost:.2f}")
    
    print(f"Total Bedrock cost (30 days): ${total_cost:.2f}")
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆ$100è¶…éï¼‰
    if total_cost > 100:
        send_cost_alert(total_cost)

def send_cost_alert(cost: float):
    sns = boto3.client('sns')
    sns.publish(
        TopicArn='arn:aws:sns:us-east-1:123456789012:bedrock-cost-alerts',
        Message=f'Bedrock cost exceeded $100: ${cost:.2f}',
        Subject='High Bedrock Cost Alert'
    )
```

### ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨é‡æœ€é©åŒ–

```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥ã§ã‚³ã‚¹ãƒˆå‰Šæ¸›
import hashlib
import redis

class CachedBedrockClient:
    def __init__(self):
        self.bedrock = BedrockTextGenerator()
        self.cache = redis.Redis(host='your-elasticache-endpoint')
        self.cache_ttl = 3600  # 1æ™‚é–“
    
    def generate_with_cache(self, prompt: str, **kwargs) -> Dict[str, Any]:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
        cache_key = hashlib.md5(
            f"{prompt}_{json.dumps(kwargs, sort_keys=True)}".encode()
        ).hexdigest()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—è©¦è¡Œ
        cached_result = self.cache.get(cache_key)
        if cached_result:
            return json.loads(cached_result)
        
        # æ–°è¦ç”Ÿæˆ
        result = self.bedrock.generate_text(prompt, **kwargs)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.cache.setex(
            cache_key, 
            self.cache_ttl, 
            json.dumps(result)
        )
        
        return result
```

## ğŸ” ç›£è¦–ã¨ãƒ­ã‚°

### AI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–

```python
import boto3
from datetime import datetime

def log_ai_interaction(
    user_id: str,
    interaction_type: str,
    input_data: Dict,
    output_data: Dict,
    model_id: str,
    cost_estimate: float = None
):
    """AIç›¸äº’ä½œç”¨ã®ãƒ­ã‚°è¨˜éŒ²"""
    
    cloudwatch = boto3.client('cloudwatch')
    dynamodb = boto3.resource('dynamodb')
    
    # CloudWatch ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    cloudwatch.put_metric_data(
        Namespace='AI/Application',
        MetricData=[
            {
                'MetricName': 'Interactions',
                'Value': 1,
                'Unit': 'Count',
                'Dimensions': [
                    {
                        'Name': 'InteractionType',
                        'Value': interaction_type
                    },
                    {
                        'Name': 'ModelId',
                        'Value': model_id
                    }
                ]
            }
        ]
    )
    
    # DynamoDBè©³ç´°ãƒ­ã‚°
    table = dynamodb.Table('ai-interaction-logs')
    table.put_item(
        Item={
            'interaction_id': f"{user_id}_{int(datetime.now().timestamp())}",
            'user_id': user_id,
            'timestamp': datetime.now().isoformat(),
            'interaction_type': interaction_type,
            'model_id': model_id,
            'input_tokens': len(str(input_data).split()),
            'output_tokens': len(str(output_data).split()),
            'cost_estimate': cost_estimate or 0,
            'success': 'error' not in output_data
        }
    )
```

## ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
import boto3
import re
from typing import Dict, List

class ContentModerator:
    def __init__(self):
        self.comprehend = boto3.client('comprehend')
        self.rekognition = boto3.client('rekognition')
    
    def moderate_text(self, text: str) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        
        # æœ‰å®³èªå¥ãƒã‚§ãƒƒã‚¯
        harmful_patterns = [
            r'æš´åŠ›',
            r'å·®åˆ¥',
            r'å€‹äººæƒ…å ±',
            # ãã®ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        ]
        
        flags = []
        for pattern in harmful_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                flags.append(f'harmful_content: {pattern}')
        
        # AWS Comprehend æœ‰å®³æ€§æ¤œå‡º
        try:
            response = self.comprehend.detect_toxic_content(
                TextSegments=[{'Text': text}],
                LanguageCode='ja'
            )
            
            for result in response['ResultList']:
                for label in result['Labels']:
                    if label['Score'] > 0.7:  # é–¾å€¤
                        flags.append(f'toxic: {label["Name"]}')
        
        except Exception as e:
            flags.append(f'moderation_error: {str(e)}')
        
        return {
            'is_safe': len(flags) == 0,
            'flags': flags,
            'confidence': 1.0 - (len(flags) * 0.2)
        }
    
    def moderate_image(self, image_bytes: bytes) -> Dict[str, Any]:
        """ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        
        try:
            response = self.rekognition.detect_moderation_labels(
                Image={'Bytes': image_bytes},
                MinConfidence=70
            )
            
            flags = []
            for label in response['ModerationLabels']:
                flags.append(f"{label['Name']}: {label['Confidence']:.1f}%")
            
            return {
                'is_safe': len(flags) == 0,
                'flags': flags
            }
            
        except Exception as e:
            return {
                'is_safe': False,
                'flags': [f'moderation_error: {str(e)}']
            }
```

## ğŸ“š å‚è€ƒè³‡æ–™

### AWS ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/)
- [Generative AI on AWS](https://aws.amazon.com/generative-ai/)
- [MLOps on AWS](https://aws.amazon.com/machine-learning/mlops/)

### AI/MLå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LangChain Documentation](https://python.langchain.com/)
- [Hugging Face Transformers](https://huggingface.co/transformers/)

## ğŸ“ˆ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

å®Œäº†å¾Œã¯ä»¥ä¸‹ã«é€²ã‚“ã§ãã ã•ã„ï¼š

1. **[CI-CDé«˜åº¦åŒ–ç·¨](../06-CI-CDé«˜åº¦åŒ–ç·¨/README.md)** - MLOps ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
2. **[Claude Code & Bedrockç·¨](../07-Claude-Code-Bedrock-AIé§†å‹•é–‹ç™ºç·¨/README.md)** - AIé§†å‹•é–‹ç™º
3. **ç‹¬è‡ªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™º** - å­¦ç¿’ã—ãŸæŠ€è¡“ã®å¿œç”¨

---

## ğŸ¯ å­¦ç¿’ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### BedrockåŸºç¤
- [ ] Bedrockã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹
- [ ] ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆAPIå®Ÿè£…
- [ ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- [ ] ã‚³ã‚¹ãƒˆç›£è¦–è¨­å®š

### AIæ©Ÿèƒ½å®Ÿè£…
- [ ] ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½œæˆï¼ˆUI + ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰
- [ ] RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰
- [ ] ç”»åƒç”Ÿæˆæ©Ÿèƒ½å®Ÿè£…
- [ ] ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

### çµ±åˆãƒ»é‹ç”¨
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- [ ] ç›£è¦–ãƒ»ãƒ­ã‚°è¨­å®š
- [ ] A/Bãƒ†ã‚¹ãƒˆå®Ÿè£…

**æº–å‚™ãŒã§ããŸã‚‰æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸é€²ã¿ã¾ã—ã‚‡ã†ï¼**