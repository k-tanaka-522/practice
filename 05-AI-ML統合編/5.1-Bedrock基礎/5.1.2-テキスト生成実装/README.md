# 5.1.2 ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Ÿè£…

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã¯ã€Amazon Bedrockã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ©Ÿèƒ½ã®å®Ÿè£…ã«ã¤ã„ã¦å­¦ç¿’ã—ã¾ã™ã€‚åŸºæœ¬çš„ãªAPIå‘¼ã³å‡ºã—ã‹ã‚‰ã€å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰ã¾ã§ã€åŒ…æ‹¬çš„ã«ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚

## ğŸ“‹ å‰ææ¡ä»¶

### å¿…é ˆã®å®Œäº†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- 1.1.1 AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šã¨IAM
- 5.1.1 Bedrockã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### æŠ€è¡“è¦ä»¶
- Python 3.8ä»¥ä¸Šã¾ãŸã¯Node.js 16ä»¥ä¸Š
- AWS CLI v2.0ä»¥ä¸Š
- AWS SDKã®åŸºæœ¬çš„ãªä½¿ç”¨çµŒé¨“
- REST APIã®ç†è§£

### æ¨©é™è¦ä»¶
- BedrockåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™
- Lambdaé–¢æ•°ã®ä½œæˆãƒ»å®Ÿè¡Œæ¨©é™
- CloudWatch Logsã¸ã®æ›¸ãè¾¼ã¿æ¨©é™

## ğŸ¯ å­¦ç¿’ç›®æ¨™

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š

1. **é«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æŠ€è¡“ã®ç¿’å¾—**
   - åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
   - Few-shot learningã®å®Ÿè£…
   - Chain-of-Thoughtãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°

2. **å¤šæ§˜ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ©Ÿèƒ½ã®å®Ÿè£…**
   - å‰µä½œæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ 
   - æ–‡æ›¸è¦ç´„ãƒ»ç¿»è¨³æ©Ÿèƒ½
   - ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ

3. **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã®å®Ÿè£…**
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”æ©Ÿèƒ½
   - é•·æ–‡ç”Ÿæˆã®æœ€é©åŒ–
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã®å‘ä¸Š

4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨æœ€é©åŒ–**
   - ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
   - ã‚³ã‚¹ãƒˆåŠ¹ç‡çš„ãªå®Ÿè£…
   - å“è³ªç®¡ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

5. **Lambdaé–¢æ•°ã‚’ç”¨ã„ãŸã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹å®Ÿè£…**
   - API Gatewayé€£æº
   - ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
   - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‡ãƒ—ãƒ­ã‚¤

## ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

### ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å›³

```mermaid
graph TB
    subgraph "Frontend Layer"
        WEB[Web Application]
        MOBILE[Mobile App]
        CLI[CLI Tool]
    end

    subgraph "API Gateway Layer"
        APIGW[API Gateway]
        AUTH[Cognito Auth]
    end

    subgraph "Application Layer"
        LAMBDA1[Text Generator<br/>Lambda]
        LAMBDA2[Document Processor<br/>Lambda]
        LAMBDA3[Code Assistant<br/>Lambda]
        LAMBDA4[Translation Service<br/>Lambda]
    end

    subgraph "Amazon Bedrock"
        CLAUDE[Claude 3 Models]
        TITAN[Titan Models]
        LLAMA[Llama 2 Models]
    end

    subgraph "Storage & Monitoring"
        S3[S3 Bucket<br/>Prompt Templates]
        CWL[CloudWatch Logs]
        CWM[CloudWatch Metrics]
        SNS[SNS Notifications]
    end

    WEB --> APIGW
    MOBILE --> APIGW
    CLI --> APIGW
    
    APIGW --> AUTH
    APIGW --> LAMBDA1
    APIGW --> LAMBDA2
    APIGW --> LAMBDA3
    APIGW --> LAMBDA4
    
    LAMBDA1 --> CLAUDE
    LAMBDA2 --> TITAN
    LAMBDA3 --> CLAUDE
    LAMBDA4 --> LLAMA
    
    LAMBDA1 --> S3
    LAMBDA2 --> S3
    LAMBDA3 --> S3
    LAMBDA4 --> S3
    
    LAMBDA1 --> CWL
    LAMBDA2 --> CWL
    LAMBDA3 --> CWL
    LAMBDA4 --> CWL
    
    CWL --> CWM
    CWM --> SNS
```

### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

1. **API Gateway**: RESTful APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
2. **Lambda Functions**: ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
3. **Bedrock Models**: å¤šæ§˜ãªç”ŸæˆAIãƒ¢ãƒ‡ãƒ«
4. **S3**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜
5. **CloudWatch**: ç›£è¦–ã¨ãƒ­ã‚°ç®¡ç†

## ğŸ›  ãƒãƒ³ã‚ºã‚ªãƒ³å®Ÿè£…

### ã‚¹ãƒ†ãƒƒãƒ—1: CloudFormationã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£

#### 1.1 åŸºæœ¬ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ä½œæˆ

```yaml
# cloudformation/text-generation-infrastructure.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'Text Generation Infrastructure with Bedrock'

Parameters:
  ProjectName:
    Type: String
    Default: 'AI-TextGen'
    Description: 'Project name for resource naming'
  
  Environment:
    Type: String
    Default: 'dev'
    AllowedValues: ['dev', 'staging', 'prod']
    Description: 'Environment name'

Resources:
  # S3 Bucket for prompt templates and outputs
  PromptTemplatesBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${ProjectName}-${Environment}-prompt-templates'
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldVersions
            Status: Enabled
            NoncurrentVersionExpirationInDays: 30

  # Lambda Execution Role
  TextGenerationExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-${Environment}-TextGen-Role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: BedrockAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                Resource:
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0'
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/amazon.titan-text-express-v1'
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                Resource: !Sub '${PromptTemplatesBucket}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !Ref PromptTemplatesBucket

  # CloudWatch Log Groups
  TextGeneratorLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${ProjectName}-${Environment}-text-generator'
      RetentionInDays: 14

  DocumentProcessorLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${ProjectName}-${Environment}-document-processor'
      RetentionInDays: 14

  CodeAssistantLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${ProjectName}-${Environment}-code-assistant'
      RetentionInDays: 14

  # API Gateway
  TextGenerationAPI:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub '${ProjectName}-${Environment}-TextGenAPI'
      Description: 'Text Generation API using Bedrock'
      EndpointConfiguration:
        Types:
          - REGIONAL
      Policy:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal: '*'
            Action: execute-api:Invoke
            Resource: '*'

  # API Gateway Deployment
  APIDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn:
      - TextGeneratorMethod
      - DocumentProcessorMethod
      - CodeAssistantMethod
    Properties:
      RestApiId: !Ref TextGenerationAPI
      StageName: !Ref Environment

Outputs:
  PromptTemplatesBucket:
    Description: 'S3 Bucket for prompt templates'
    Value: !Ref PromptTemplatesBucket
    Export:
      Name: !Sub '${ProjectName}-${Environment}-PromptTemplatesBucket'

  TextGenerationExecutionRole:
    Description: 'Lambda execution role ARN'
    Value: !GetAtt TextGenerationExecutionRole.Arn
    Export:
      Name: !Sub '${ProjectName}-${Environment}-ExecutionRole'

  APIGatewayURL:
    Description: 'API Gateway URL'
    Value: !Sub 'https://${TextGenerationAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}'
    Export:
      Name: !Sub '${ProjectName}-${Environment}-APIURL'
```

#### 1.2 Lambdaé–¢æ•°ã®å®Ÿè£…

##### ãƒ†ã‚­ã‚¹ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ Lambdaé–¢æ•°

```python
# lambda/text-generator/lambda_function.py
import json
import boto3
import logging
from typing import Dict, Any, Optional
from botocore.exceptions import ClientError
import time

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Bedrockã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
bedrock_runtime = boto3.client('bedrock-runtime')
s3_client = boto3.client('s3')

# ç’°å¢ƒå¤‰æ•°
PROMPT_TEMPLATES_BUCKET = os.environ.get('PROMPT_TEMPLATES_BUCKET')

class TextGenerationError(Exception):
    """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–"""
    pass

def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """
    ãƒ¡ã‚¤ãƒ³ã®Lambda ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°
    """
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®è§£æ
        if 'body' in event:
            body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
        else:
            body = event
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
        text_type = body.get('type', 'general')
        prompt = body.get('prompt', '')
        model_id = body.get('model_id', 'anthropic.claude-3-haiku-20240307-v1:0')
        parameters = body.get('parameters', {})
        
        # å…¥åŠ›æ¤œè¨¼
        if not prompt.strip():
            raise ValueError("Prompt cannot be empty")
        
        logger.info(f"Generating text of type: {text_type}, model: {model_id}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Ÿè¡Œ
        result = generate_text(
            text_type=text_type,
            prompt=prompt,
            model_id=model_id,
            parameters=parameters
        )
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type, Authorization'
            },
            'body': json.dumps({
                'success': True,
                'result': result,
                'metadata': {
                    'model_id': model_id,
                    'text_type': text_type,
                    'timestamp': int(time.time())
                }
            }, ensure_ascii=False)
        }
        
    except ValueError as e:
        logger.error(f"Validation error: {str(e)}")
        return error_response(400, str(e))
    
    except TextGenerationError as e:
        logger.error(f"Text generation error: {str(e)}")
        return error_response(500, str(e))
    
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        return error_response(500, "Internal server error")

def generate_text(text_type: str, prompt: str, model_id: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    """
    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—
        enhanced_prompt = enhance_prompt_with_template(text_type, prompt)
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰
        if model_id.startswith('anthropic.claude'):
            result = generate_with_claude(enhanced_prompt, model_id, parameters)
        elif model_id.startswith('amazon.titan'):
            result = generate_with_titan(enhanced_prompt, model_id, parameters)
        else:
            raise TextGenerationError(f"Unsupported model: {model_id}")
        
        return result
        
    except ClientError as e:
        error_code = e.response['Error']['Code']
        error_message = e.response['Error']['Message']
        
        if error_code == 'ValidationException':
            raise TextGenerationError(f"Invalid request: {error_message}")
        elif error_code == 'ThrottlingException':
            raise TextGenerationError("Rate limit exceeded. Please try again later.")
        elif error_code == 'AccessDeniedException':
            raise TextGenerationError("Access denied to the model")
        else:
            raise TextGenerationError(f"Bedrock error: {error_message}")

def enhance_prompt_with_template(text_type: str, user_prompt: str) -> str:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–
    """
    try:
        template_key = f"templates/{text_type}.txt"
        
        # S3ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        response = s3_client.get_object(
            Bucket=PROMPT_TEMPLATES_BUCKET,
            Key=template_key
        )
        template = response['Body'].read().decode('utf-8')
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ¿å…¥
        enhanced_prompt = template.replace('{user_prompt}', user_prompt)
        
        logger.info(f"Enhanced prompt using template: {text_type}")
        return enhanced_prompt
        
    except ClientError as e:
        if e.response['Error']['Code'] == 'NoSuchKey':
            logger.warning(f"Template not found for type: {text_type}, using default")
            return get_default_template(text_type, user_prompt)
        else:
            logger.error(f"Error fetching template: {e}")
            return user_prompt

def get_default_template(text_type: str, user_prompt: str) -> str:
    """
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™
    """
    templates = {
        'creative_writing': f"""ã‚ãªãŸã¯å‰µä½œã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€é­…åŠ›çš„ã§å‰µé€ çš„ãªæ–‡ç« ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

ä»¥ä¸‹ã®ç‚¹ã‚’æ„è­˜ã—ã¦åŸ·ç­†ã—ã¦ãã ã•ã„ï¼š
- èª­è€…ã‚’å¼•ãã¤ã‘ã‚‹é­…åŠ›çš„ãªå°å…¥
- å…·ä½“çš„ã§é®®æ˜ãªæå†™
- é©åˆ‡ãªæ–‡ä½“ã¨ãƒˆãƒ¼ãƒ³
- èª­ã¿ã‚„ã™ã„æ§‹æˆ

åŸ·ç­†:""",

        'business_writing': f"""ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæ–‡æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

ä»¥ä¸‹ã®ç‚¹ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ï¼š
- æ˜ç¢ºã§ç°¡æ½”ãªè¡¨ç¾
- è«–ç†çš„ãªæ§‹æˆ
- ãƒ“ã‚¸ãƒã‚¹ã«é©ã—ãŸæ•¬èªã¨è¡¨ç¾
- ç›®çš„ã«åˆã£ãŸå½¢å¼

æ–‡æ›¸:""",

        'academic_writing': f"""ã‚ãªãŸã¯å­¦è¡“è«–æ–‡ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€å­¦è¡“çš„ãªæ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

å­¦è¡“æ–‡æ›¸ã®è¦ä»¶ï¼š
- å®¢è¦³çš„ã§è«–ç†çš„ãªè¨˜è¿°
- é©åˆ‡ãªå¼•ç”¨å½¢å¼
- å°‚é–€ç”¨èªã®é©åˆ‡ãªä½¿ç”¨
- æ§‹é€ åŒ–ã•ã‚ŒãŸè«–è¿°

è«–è¿°:""",

        'translation': f"""ã‚ãªãŸã¯ç¿»è¨³ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã•ã‚ŒãŸè¨€èªã«æ­£ç¢ºã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

ç¿»è¨³æ™‚ã®æ³¨æ„äº‹é …ï¼š
- åŸæ–‡ã®æ„å‘³ã‚’æ­£ç¢ºã«ä¼ãˆã‚‹
- è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨
- æ–‡åŒ–çš„ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’è€ƒæ…®
- å°‚é–€ç”¨èªã¯é©åˆ‡ã«ç¿»è¨³

ç¿»è¨³:""",

        'code_explanation': f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯æŠ€è¡“çš„ãªè³ªå•ã«ã¤ã„ã¦ã€è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚

è³ªå•/ã‚³ãƒ¼ãƒ‰: {user_prompt}

èª¬æ˜ã«å«ã‚ã‚‹ã¹ãè¦ç´ ï¼š
- ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œåŸç†
- ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- æ”¹å–„ç‚¹ã‚„æ³¨æ„äº‹é …
- å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹

èª¬æ˜:""",

        'summarization': f"""ã‚ãªãŸã¯æ–‡æ›¸è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç°¡æ½”ã§è¦ç‚¹ã‚’æŠ¼ã•ãˆãŸè¦ç´„ã«ã—ã¦ãã ã•ã„ã€‚

è¦ç´„å¯¾è±¡: {user_prompt}

è¦ç´„ã®è¦ä»¶ï¼š
- ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ¼ã‚‰ã•ãªã„
- ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„è¡¨ç¾
- è«–ç†çš„ãªæ§‹æˆ
- åŸæ–‡ã®é‡è¦åº¦ã«åŸºã¥ãæƒ…å ±ã®å–æ¨é¸æŠ

è¦ç´„:"""
    }
    
    return templates.get(text_type, f"ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦é©åˆ‡ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ï¼š\n\n{user_prompt}")

def generate_with_claude(prompt: str, model_id: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """
    Claude ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    default_params = {
        'max_tokens': 1000,
        'temperature': 0.7,
        'top_p': 0.9
    }
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
    params = {**default_params, **parameters}
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®æ§‹ç¯‰
    body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": params['max_tokens'],
        "temperature": params['temperature'],
        "top_p": params['top_p'],
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }
    
    # Bedrock APIå‘¼ã³å‡ºã—
    response = bedrock_runtime.invoke_model(
        modelId=model_id,
        body=json.dumps(body)
    )
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
    response_body = json.loads(response['body'].read())
    generated_text = response_body['content'][0]['text']
    
    return {
        'generated_text': generated_text,
        'input_tokens': response_body.get('usage', {}).get('input_tokens', 0),
        'output_tokens': response_body.get('usage', {}).get('output_tokens', 0),
        'model_id': model_id
    }

def generate_with_titan(prompt: str, model_id: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """
    Titan ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    default_params = {
        'maxTokenCount': 1000,
        'temperature': 0.7,
        'topP': 0.9
    }
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
    params = {**default_params, **parameters}
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®æ§‹ç¯‰
    body = {
        "inputText": prompt,
        "textGenerationConfig": {
            "maxTokenCount": params['maxTokenCount'],
            "temperature": params['temperature'],
            "topP": params['topP'],
            "stopSequences": []
        }
    }
    
    # Bedrock APIå‘¼ã³å‡ºã—
    response = bedrock_runtime.invoke_model(
        modelId=model_id,
        body=json.dumps(body)
    )
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
    response_body = json.loads(response['body'].read())
    generated_text = response_body['results'][0]['outputText']
    
    return {
        'generated_text': generated_text,
        'input_tokens': response_body.get('inputTextTokenCount', 0),
        'output_tokens': response_body.get('results', [{}])[0].get('tokenCount', 0),
        'model_id': model_id
    }

def error_response(status_code: int, message: str) -> Dict[str, Any]:
    """
    ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
    """
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps({
            'success': False,
            'error': message,
            'timestamp': int(time.time())
        }, ensure_ascii=False)
    }
```

##### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ†ã‚­ã‚¹ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼

```python
# lambda/streaming-text-generator/lambda_function.py
import json
import boto3
import logging
from typing import Dict, Any, Iterator
from botocore.exceptions import ClientError
import base64

logger = logging.getLogger()
logger.setLevel(logging.INFO)

bedrock_runtime = boto3.client('bedrock-runtime')

def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆLambdaé–¢æ•°
    """
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®è§£æ
        if 'body' in event:
            body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
        else:
            body = event
        
        prompt = body.get('prompt', '')
        model_id = body.get('model_id', 'anthropic.claude-3-haiku-20240307-v1:0')
        stream = body.get('stream', False)
        
        if not prompt.strip():
            raise ValueError("Prompt cannot be empty")
        
        if stream:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            return handle_streaming_request(prompt, model_id, body.get('parameters', {}))
        else:
            # é€šå¸¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            return handle_normal_request(prompt, model_id, body.get('parameters', {}))
            
    except Exception as e:
        logger.error(f"Error in streaming handler: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }

def handle_streaming_request(prompt: str, model_id: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†
    """
    # Claudeç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": parameters.get('max_tokens', 1000),
        "temperature": parameters.get('temperature', 0.7),
        "top_p": parameters.get('top_p', 0.9),
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }
    
    try:
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIã®å‘¼ã³å‡ºã—
        response = bedrock_runtime.invoke_model_with_response_stream(
            modelId=model_id,
            body=json.dumps(body)
        )
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿åé›†
        full_response = ""
        event_stream = response['body']
        
        for event in event_stream:
            if 'chunk' in event:
                chunk = json.loads(event['chunk']['bytes'].decode())
                if chunk['type'] == 'content_block_delta':
                    if 'delta' in chunk and 'text' in chunk['delta']:
                        text_chunk = chunk['delta']['text']
                        full_response += text_chunk
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'generated_text': full_response,
                'stream': True,
                'model_id': model_id
            }, ensure_ascii=False)
        }
        
    except ClientError as e:
        logger.error(f"Bedrock streaming error: {e}")
        raise

def handle_normal_request(prompt: str, model_id: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """
    é€šå¸¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
    """
    body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": parameters.get('max_tokens', 1000),
        "temperature": parameters.get('temperature', 0.7),
        "top_p": parameters.get('top_p', 0.9),
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }
    
    response = bedrock_runtime.invoke_model(
        modelId=model_id,
        body=json.dumps(body)
    )
    
    response_body = json.loads(response['body'].read())
    generated_text = response_body['content'][0]['text']
    
    return {
        'statusCode': 200,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps({
            'generated_text': generated_text,
            'stream': False,
            'model_id': model_id,
            'usage': response_body.get('usage', {})
        }, ensure_ascii=False)
    }
```

#### 1.3 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ

```bash
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆã¨S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
mkdir -p templates

# å‰µä½œæ”¯æ´ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
cat > templates/creative_writing.txt << 'EOF'
ã‚ãªãŸã¯å‰µä½œã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚èª­è€…ã‚’å¼•ãã¤ã‘ã‚‹é­…åŠ›çš„ãªæ–‡ç« ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

å‰µä½œã®æŒ‡é‡ï¼š
1. é®®æ˜ã§å…·ä½“çš„ãªæå†™ã‚’å¿ƒãŒã‘ã‚‹
2. æ„Ÿæƒ…ã«è¨´ãˆã‹ã‘ã‚‹è¡¨ç¾ã‚’ä½¿ç”¨
3. é©åˆ‡ãªãƒšãƒ¼ã‚¹ã§ç‰©èªã‚’å±•é–‹
4. èª­è€…ã®æƒ³åƒåŠ›ã‚’åˆºæ¿€ã™ã‚‹
5. æ–‡ä½“ã¨ãƒˆãƒ¼ãƒ³ã‚’çµ±ä¸€ã™ã‚‹

å‰µä½œ:
EOF

# ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
cat > templates/business_writing.txt << 'EOF'
ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§åŠ¹æœçš„ãªæ–‡æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®è¦ä»¶ï¼š
1. æ˜ç¢ºã§ç°¡æ½”ãªè¡¨ç¾
2. è«–ç†çš„ã§æ§‹é€ åŒ–ã•ã‚ŒãŸå†…å®¹
3. é©åˆ‡ãªæ•¬èªã¨è¡¨ç¾
4. ç›®çš„ã«åˆã£ãŸå½¢å¼ã¨ãƒˆãƒ¼ãƒ³
5. å®Ÿè¡Œå¯èƒ½ãªå…·ä½“æ€§

æ–‡æ›¸:
EOF

# å­¦è¡“è«–æ–‡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
cat > templates/academic_writing.txt << 'EOF'
ã‚ãªãŸã¯å­¦è¡“è«–æ–‡ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚å­¦è¡“çš„ãªåŸºæº–ã«å¾“ã£ã¦æ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

å­¦è¡“æ–‡æ›¸ã®è¦ä»¶ï¼š
1. å®¢è¦³çš„ã§è«–ç†çš„ãªè¨˜è¿°
2. æ ¹æ‹ ã«åŸºã¥ã„ãŸä¸»å¼µ
3. é©åˆ‡ãªå°‚é–€ç”¨èªã®ä½¿ç”¨
4. æ§‹é€ åŒ–ã•ã‚ŒãŸè«–è¿°
5. æ‰¹åˆ¤çš„æ€è€ƒã®åæ˜ 

è«–è¿°:
EOF

# ã‚³ãƒ¼ãƒ‰èª¬æ˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
cat > templates/code_explanation.txt << 'EOF'
ã‚ãªãŸã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚æŠ€è¡“çš„ãªå†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {user_prompt}

èª¬æ˜ã®è¦ä»¶ï¼š
1. ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œåŸç†ã‚’æ˜ç¢ºã«èª¬æ˜
2. ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£èª¬
3. æ”¹å–„ç‚¹ã‚„æ³¨æ„äº‹é …ã®æŒ‡æ‘˜
4. å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹ã®æç¤º
5. åˆå¿ƒè€…ã«ã‚‚ç†è§£ã§ãã‚‹è¡¨ç¾

èª¬æ˜:
EOF

# è¦ç´„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
cat > templates/summarization.txt << 'EOF'
ã‚ãªãŸã¯æ–‡æ›¸è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚åŠ¹æœçš„ã§æ­£ç¢ºãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

è¦ç´„å¯¾è±¡: {user_prompt}

è¦ç´„ã®è¦ä»¶ï¼š
1. ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ¼ã‚‰ã•ãªã„
2. ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„è¡¨ç¾
3. è«–ç†çš„ãªæ§‹æˆã®ç¶­æŒ
4. é‡è¦åº¦ã«åŸºã¥ãæƒ…å ±ã®å–æ¨é¸æŠ
5. åŸæ–‡ã®æ„å›³ã‚’æ­£ç¢ºã«åæ˜ 

è¦ç´„:
EOF
```

### ã‚¹ãƒ†ãƒƒãƒ—2: Lambdaé–¢æ•°ã®ãƒ‡ãƒ—ãƒ­ã‚¤

#### 2.1 ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç”¨CloudFormationãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```yaml
# cloudformation/lambda-functions.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'Lambda functions for text generation'

Parameters:
  ProjectName:
    Type: String
    Default: 'AI-TextGen'
  
  Environment:
    Type: String
    Default: 'dev'
  
  ExecutionRoleArn:
    Type: String
    Description: 'Lambda execution role ARN'
  
  PromptTemplatesBucket:
    Type: String
    Description: 'S3 bucket for prompt templates'

Resources:
  # Text Generator Lambda Function
  TextGeneratorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-${Environment}-text-generator'
      Runtime: python3.11
      Handler: lambda_function.lambda_handler
      Role: !Ref ExecutionRoleArn
      Timeout: 300
      MemorySize: 512
      Environment:
        Variables:
          PROMPT_TEMPLATES_BUCKET: !Ref PromptTemplatesBucket
          LOG_LEVEL: INFO
      Code:
        ZipFile: |
          # Placeholder code - will be updated with deployment
          def lambda_handler(event, context):
              return {'statusCode': 200, 'body': 'Function not yet deployed'}

  # Streaming Text Generator Lambda Function
  StreamingTextGeneratorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-${Environment}-streaming-text-generator'
      Runtime: python3.11
      Handler: lambda_function.lambda_handler
      Role: !Ref ExecutionRoleArn
      Timeout: 300
      MemorySize: 512
      Code:
        ZipFile: |
          # Placeholder code - will be updated with deployment
          def lambda_handler(event, context):
              return {'statusCode': 200, 'body': 'Function not yet deployed'}

  # Document Processor Lambda Function
  DocumentProcessorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-${Environment}-document-processor'
      Runtime: python3.11
      Handler: lambda_function.lambda_handler
      Role: !Ref ExecutionRoleArn
      Timeout: 600
      MemorySize: 1024
      Environment:
        Variables:
          PROMPT_TEMPLATES_BUCKET: !Ref PromptTemplatesBucket
          MAX_DOCUMENT_SIZE: '1048576'  # 1MB
      Code:
        ZipFile: |
          # Placeholder code - will be updated with deployment
          def lambda_handler(event, context):
              return {'statusCode': 200, 'body': 'Function not yet deployed'}

  # API Gateway Lambda Permissions
  TextGeneratorAPIPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref TextGeneratorFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:*/*/*/*'

  StreamingTextGeneratorAPIPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref StreamingTextGeneratorFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:*/*/*/*'

  DocumentProcessorAPIPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DocumentProcessorFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:*/*/*/*'

Outputs:
  TextGeneratorFunctionArn:
    Description: 'Text Generator Lambda Function ARN'
    Value: !GetAtt TextGeneratorFunction.Arn
    Export:
      Name: !Sub '${ProjectName}-${Environment}-TextGeneratorArn'

  StreamingTextGeneratorFunctionArn:
    Description: 'Streaming Text Generator Lambda Function ARN'
    Value: !GetAtt StreamingTextGeneratorFunction.Arn
    Export:
      Name: !Sub '${ProjectName}-${Environment}-StreamingTextGeneratorArn'

  DocumentProcessorFunctionArn:
    Description: 'Document Processor Lambda Function ARN'
    Value: !GetAtt DocumentProcessorFunction.Arn
    Export:
      Name: !Sub '${ProjectName}-${Environment}-DocumentProcessorArn'
```

#### 2.2 ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/deploy-lambda-functions.sh

set -e

PROJECT_NAME="AI-TextGen"
ENVIRONMENT="dev"
REGION="us-east-1"

echo "Deploying Lambda functions for ${PROJECT_NAME}-${ENVIRONMENT}..."

# Lambdaé–¢æ•°ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
package_lambda_function() {
    local function_name=$1
    local source_dir=$2
    
    echo "Packaging ${function_name}..."
    
    cd ${source_dir}
    
    # ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    if [ -f requirements.txt ]; then
        pip install -r requirements.txt -t .
    fi
    
    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
    zip -r "../${function_name}.zip" . -x "*.pyc" "*.pyo" "*__pycache__*" "*.git*"
    
    cd ..
}

# Lambdaé–¢æ•°ã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
update_lambda_function() {
    local function_name=$1
    local zip_file=$2
    
    echo "Updating ${function_name}..."
    
    aws lambda update-function-code \
        --function-name "${PROJECT_NAME}-${ENVIRONMENT}-${function_name}" \
        --zip-file "fileb://${zip_file}" \
        --region ${REGION}
}

# å„Lambdaé–¢æ•°ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤
package_lambda_function "text-generator" "lambda/text-generator"
package_lambda_function "streaming-text-generator" "lambda/streaming-text-generator"
package_lambda_function "document-processor" "lambda/document-processor"

# Lambdaé–¢æ•°ã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
update_lambda_function "text-generator" "text-generator.zip"
update_lambda_function "streaming-text-generator" "streaming-text-generator.zip"
update_lambda_function "document-processor" "document-processor.zip"

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
echo "Uploading prompt templates to S3..."
BUCKET_NAME="${PROJECT_NAME}-${ENVIRONMENT}-prompt-templates"

aws s3 sync templates/ s3://${BUCKET_NAME}/templates/ \
    --region ${REGION} \
    --delete

echo "Deployment completed successfully!"
```

### ã‚¹ãƒ†ãƒƒãƒ—3: API Gatewayè¨­å®š

#### 3.1 API Gatewayè¨­å®šç”¨CloudFormation

```yaml
# cloudformation/api-gateway.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'API Gateway configuration for text generation service'

Parameters:
  ProjectName:
    Type: String
    Default: 'AI-TextGen'
  
  Environment:
    Type: String
    Default: 'dev'
  
  TextGeneratorFunctionArn:
    Type: String
    Description: 'Text Generator Lambda Function ARN'
  
  StreamingTextGeneratorFunctionArn:
    Type: String
    Description: 'Streaming Text Generator Lambda Function ARN'
  
  DocumentProcessorFunctionArn:
    Type: String
    Description: 'Document Processor Lambda Function ARN'

Resources:
  # API Gateway Rest API
  TextGenerationAPI:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub '${ProjectName}-${Environment}-API'
      Description: 'Text Generation API using Amazon Bedrock'
      EndpointConfiguration:
        Types:
          - REGIONAL
      BinaryMediaTypes:
        - 'application/pdf'
        - 'application/msword'
        - 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'

  # Resources
  GenerateResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ParentId: !GetAtt TextGenerationAPI.RootResourceId
      PathPart: 'generate'

  StreamResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ParentId: !GetAtt TextGenerationAPI.RootResourceId
      PathPart: 'stream'

  ProcessResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ParentId: !GetAtt TextGenerationAPI.RootResourceId
      PathPart: 'process'

  # Methods for Generate endpoint
  GenerateMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ResourceId: !Ref GenerateResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${TextGeneratorFunctionArn}/invocations'
      MethodResponses:
        - StatusCode: 200
          ResponseHeaders:
            Access-Control-Allow-Origin: true
            Access-Control-Allow-Methods: true
            Access-Control-Allow-Headers: true
        - StatusCode: 400
        - StatusCode: 500

  GenerateOptionsMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ResourceId: !Ref GenerateResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              method.response.header.Access-Control-Allow-Headers: "'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token'"
              method.response.header.Access-Control-Allow-Methods: "'POST,OPTIONS'"
              method.response.header.Access-Control-Allow-Origin: "'*'"
        RequestTemplates:
          application/json: '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            method.response.header.Access-Control-Allow-Headers: true
            method.response.header.Access-Control-Allow-Methods: true
            method.response.header.Access-Control-Allow-Origin: true

  # Methods for Stream endpoint
  StreamMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ResourceId: !Ref StreamResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${StreamingTextGeneratorFunctionArn}/invocations'
      MethodResponses:
        - StatusCode: 200
          ResponseHeaders:
            Access-Control-Allow-Origin: true
        - StatusCode: 400
        - StatusCode: 500

  StreamOptionsMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref TextGenerationAPI
      ResourceId: !Ref StreamResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              method.response.header.Access-Control-Allow-Headers: "'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token'"
              method.response.header.Access-Control-Allow-Methods: "'POST,OPTIONS'"
              method.response.header.Access-Control-Allow-Origin: "'*'"
        RequestTemplates:
          application/json: '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            method.response.header.Access-Control-Allow-Headers: true
            method.response.header.Access-Control-Allow-Methods: true
            method.response.header.Access-Control-Allow-Origin: true

  # API Deployment
  APIDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn:
      - GenerateMethod
      - GenerateOptionsMethod
      - StreamMethod
      - StreamOptionsMethod
    Properties:
      RestApiId: !Ref TextGenerationAPI
      StageName: !Ref Environment
      StageDescription:
        Variables:
          version: "1.0"
        Description: !Sub 'Deployed on ${Environment} environment'

  # Usage Plan
  APIUsagePlan:
    Type: AWS::ApiGateway::UsagePlan
    Properties:
      UsagePlanName: !Sub '${ProjectName}-${Environment}-usage-plan'
      Description: 'Usage plan for text generation API'
      ApiStages:
        - ApiId: !Ref TextGenerationAPI
          Stage: !Ref Environment
      Throttle:
        RateLimit: 100
        BurstLimit: 200
      Quota:
        Limit: 10000
        Period: DAY

Outputs:
  APIGatewayURL:
    Description: 'API Gateway URL'
    Value: !Sub 'https://${TextGenerationAPI}.execute-api.${AWS::Region}.amazonaws.com/${Environment}'
    Export:
      Name: !Sub '${ProjectName}-${Environment}-APIURL'

  APIGatewayId:
    Description: 'API Gateway ID'
    Value: !Ref TextGenerationAPI
    Export:
      Name: !Sub '${ProjectName}-${Environment}-APIId'
```

### ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè£…

#### 4.1 Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
# client/python_client.py
import requests
import json
import time
from typing import Dict, Any, Optional
import argparse

class BedrockTextGenerator:
    """
    Bedrock ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    """
    
    def __init__(self, api_url: str):
        self.api_url = api_url.rstrip('/')
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'BedrockTextGenerator/1.0'
        })
    
    def generate_text(
        self,
        prompt: str,
        text_type: str = 'general',
        model_id: str = 'anthropic.claude-3-haiku-20240307-v1:0',
        parameters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        """
        if parameters is None:
            parameters = {}
        
        payload = {
            'prompt': prompt,
            'type': text_type,
            'model_id': model_id,
            'parameters': parameters
        }
        
        try:
            response = self.session.post(
                f'{self.api_url}/generate',
                json=payload,
                timeout=300
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            return {
                'success': False,
                'error': f'Request failed: {str(e)}'
            }
    
    def generate_streaming_text(
        self,
        prompt: str,
        model_id: str = 'anthropic.claude-3-haiku-20240307-v1:0',
        parameters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        """
        if parameters is None:
            parameters = {}
        
        payload = {
            'prompt': prompt,
            'model_id': model_id,
            'parameters': parameters,
            'stream': True
        }
        
        try:
            response = self.session.post(
                f'{self.api_url}/stream',
                json=payload,
                timeout=300
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            return {
                'success': False,
                'error': f'Streaming request failed: {str(e)}'
            }

def main():
    parser = argparse.ArgumentParser(description='Bedrock Text Generation Client')
    parser.add_argument('--api-url', required=True, help='API Gateway URL')
    parser.add_argument('--prompt', required=True, help='Text generation prompt')
    parser.add_argument('--type', default='general', help='Text type (creative_writing, business_writing, etc.)')
    parser.add_argument('--model', default='anthropic.claude-3-haiku-20240307-v1:0', help='Model ID')
    parser.add_argument('--stream', action='store_true', help='Use streaming API')
    parser.add_argument('--max-tokens', type=int, default=1000, help='Maximum tokens')
    parser.add_argument('--temperature', type=float, default=0.7, help='Temperature (0.0-1.0)')
    
    args = parser.parse_args()
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    client = BedrockTextGenerator(args.api_url)
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
    parameters = {
        'max_tokens': args.max_tokens,
        'temperature': args.temperature
    }
    
    print(f"Generating text with prompt: '{args.prompt[:50]}...'")
    print(f"Model: {args.model}")
    print(f"Type: {args.type}")
    print(f"Streaming: {args.stream}")
    print("-" * 50)
    
    start_time = time.time()
    
    # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®å®Ÿè¡Œ
    if args.stream:
        result = client.generate_streaming_text(
            prompt=args.prompt,
            model_id=args.model,
            parameters=parameters
        )
    else:
        result = client.generate_text(
            prompt=args.prompt,
            text_type=args.type,
            model_id=args.model,
            parameters=parameters
        )
    
    end_time = time.time()
    
    # çµæœã®è¡¨ç¤º
    if result.get('success', True):
        print("Generated Text:")
        print("=" * 50)
        if 'result' in result:
            print(result['result']['generated_text'])
            print("\nMetadata:")
            if 'input_tokens' in result['result']:
                print(f"Input tokens: {result['result']['input_tokens']}")
            if 'output_tokens' in result['result']:
                print(f"Output tokens: {result['result']['output_tokens']}")
        else:
            print(result.get('generated_text', 'No text generated'))
        
        print(f"\nGeneration time: {end_time - start_time:.2f} seconds")
    else:
        print(f"Error: {result.get('error', 'Unknown error')}")

if __name__ == '__main__':
    main()
```

#### 4.2 Web ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (HTML + JavaScript)

```html
<!-- client/web_client.html -->
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bedrock Text Generator</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .container {
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header {
            text-align: center;
            margin-bottom: 30px;
            color: #333;
        }
        
        .form-group {
            margin-bottom: 20px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 600;
            color: #555;
        }
        
        textarea, select, input {
            width: 100%;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 6px;
            font-size: 14px;
            transition: border-color 0.3s;
        }
        
        textarea:focus, select:focus, input:focus {
            outline: none;
            border-color: #4CAF50;
        }
        
        .prompt-textarea {
            min-height: 120px;
            resize: vertical;
        }
        
        .result-textarea {
            min-height: 300px;
            background-color: #f9f9f9;
            font-family: 'Courier New', monospace;
        }
        
        .button-group {
            display: flex;
            gap: 10px;
            margin: 20px 0;
        }
        
        button {
            flex: 1;
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .btn-primary {
            background-color: #4CAF50;
            color: white;
        }
        
        .btn-primary:hover {
            background-color: #45a049;
        }
        
        .btn-secondary {
            background-color: #2196F3;
            color: white;
        }
        
        .btn-secondary:hover {
            background-color: #1976D2;
        }
        
        .btn-danger {
            background-color: #f44336;
            color: white;
        }
        
        .btn-danger:hover {
            background-color: #d32f2f;
        }
        
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        
        .parameters-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
        }
        
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            font-weight: 500;
        }
        
        .status.success {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .status.info {
            background-color: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        
        .metadata {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 6px;
            margin-top: 15px;
            font-size: 14px;
            color: #666;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }
        
        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #4CAF50;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– Bedrock Text Generator</h1>
            <p>Amazon Bedrockã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ</p>
        </div>
        
        <form id="textGenerationForm">
            <div class="form-group">
                <label for="apiUrl">API URL:</label>
                <input type="url" id="apiUrl" placeholder="https://your-api-gateway-url.amazonaws.com/dev" required>
            </div>
            
            <div class="form-group">
                <label for="textType">ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ—:</label>
                <select id="textType">
                    <option value="general">ä¸€èˆ¬</option>
                    <option value="creative_writing">å‰µä½œæ”¯æ´</option>
                    <option value="business_writing">ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸</option>
                    <option value="academic_writing">å­¦è¡“è«–æ–‡</option>
                    <option value="code_explanation">ã‚³ãƒ¼ãƒ‰èª¬æ˜</option>
                    <option value="summarization">è¦ç´„</option>
                    <option value="translation">ç¿»è¨³</option>
                </select>
            </div>
            
            <div class="form-group">
                <label for="modelId">ãƒ¢ãƒ‡ãƒ«:</label>
                <select id="modelId">
                    <option value="anthropic.claude-3-haiku-20240307-v1:0">Claude 3 Haiku (é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ)</option>
                    <option value="anthropic.claude-3-sonnet-20240229-v1:0">Claude 3 Sonnet (ãƒãƒ©ãƒ³ã‚¹å‹)</option>
                    <option value="amazon.titan-text-express-v1">Amazon Titan Express</option>
                </select>
            </div>
            
            <div class="form-group">
                <label for="prompt">ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:</label>
                <textarea id="prompt" class="prompt-textarea" placeholder="ã“ã“ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..." required></textarea>
            </div>
            
            <div class="parameters-grid">
                <div class="form-group">
                    <label for="maxTokens">æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°:</label>
                    <input type="number" id="maxTokens" value="1000" min="1" max="4000">
                </div>
                
                <div class="form-group">
                    <label for="temperature">Temperature:</label>
                    <input type="number" id="temperature" value="0.7" min="0" max="1" step="0.1">
                </div>
                
                <div class="form-group">
                    <label for="topP">Top P:</label>
                    <input type="number" id="topP" value="0.9" min="0" max="1" step="0.1">
                </div>
            </div>
            
            <div class="button-group">
                <button type="submit" class="btn-primary" id="generateBtn">
                    ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
                </button>
                <button type="button" class="btn-secondary" id="streamBtn">
                    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
                </button>
                <button type="button" class="btn-danger" id="clearBtn">
                    ã‚¯ãƒªã‚¢
                </button>
            </div>
        </form>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆä¸­...</p>
        </div>
        
        <div id="status"></div>
        
        <div class="form-group">
            <label for="result">ç”Ÿæˆçµæœ:</label>
            <textarea id="result" class="result-textarea" readonly></textarea>
        </div>
        
        <div id="metadata" class="metadata" style="display: none;"></div>
    </div>

    <script>
        class TextGeneratorClient {
            constructor() {
                this.initEventListeners();
            }
            
            initEventListeners() {
                document.getElementById('textGenerationForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.generateText(false);
                });
                
                document.getElementById('streamBtn').addEventListener('click', () => {
                    this.generateText(true);
                });
                
                document.getElementById('clearBtn').addEventListener('click', () => {
                    this.clearResults();
                });
            }
            
            async generateText(streaming = false) {
                const apiUrl = document.getElementById('apiUrl').value.trim();
                const textType = document.getElementById('textType').value;
                const modelId = document.getElementById('modelId').value;
                const prompt = document.getElementById('prompt').value.trim();
                const maxTokens = parseInt(document.getElementById('maxTokens').value);
                const temperature = parseFloat(document.getElementById('temperature').value);
                const topP = parseFloat(document.getElementById('topP').value);
                
                if (!apiUrl || !prompt) {
                    this.showStatus('API URLã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚', 'error');
                    return;
                }
                
                this.setLoading(true);
                this.clearResults();
                
                const endpoint = streaming ? '/stream' : '/generate';
                const payload = {
                    prompt: prompt,
                    type: textType,
                    model_id: modelId,
                    parameters: {
                        max_tokens: maxTokens,
                        temperature: temperature,
                        top_p: topP
                    }
                };
                
                if (streaming) {
                    payload.stream = true;
                }
                
                try {
                    const startTime = Date.now();
                    
                    const response = await fetch(apiUrl + endpoint, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify(payload)
                    });
                    
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    
                    const result = await response.json();
                    const endTime = Date.now();
                    const duration = (endTime - startTime) / 1000;
                    
                    this.displayResult(result, duration, streaming);
                    
                } catch (error) {
                    console.error('Generation error:', error);
                    this.showStatus(`ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error.message}`, 'error');
                } finally {
                    this.setLoading(false);
                }
            }
            
            displayResult(result, duration, streaming) {
                if (result.success === false) {
                    this.showStatus(`ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ${result.error}`, 'error');
                    return;
                }
                
                let generatedText = '';
                let metadata = {};
                
                if (result.result) {
                    // é€šå¸¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                    generatedText = result.result.generated_text;
                    metadata = {
                        model_id: result.result.model_id,
                        input_tokens: result.result.input_tokens,
                        output_tokens: result.result.output_tokens,
                        duration: duration
                    };
                } else if (result.generated_text) {
                    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                    generatedText = result.generated_text;
                    metadata = {
                        model_id: result.model_id,
                        streaming: streaming,
                        duration: duration
                    };
                }
                
                document.getElementById('result').value = generatedText;
                this.showStatus('ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚', 'success');
                this.displayMetadata(metadata);
            }
            
            displayMetadata(metadata) {
                const metadataDiv = document.getElementById('metadata');
                let html = '<h3>ç”Ÿæˆæƒ…å ±</h3>';
                
                for (const [key, value] of Object.entries(metadata)) {
                    const label = this.getMetadataLabel(key);
                    html += `<p><strong>${label}:</strong> ${value}</p>`;
                }
                
                metadataDiv.innerHTML = html;
                metadataDiv.style.display = 'block';
            }
            
            getMetadataLabel(key) {
                const labels = {
                    model_id: 'ãƒ¢ãƒ‡ãƒ«ID',
                    input_tokens: 'å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°',
                    output_tokens: 'å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°',
                    duration: 'ç”Ÿæˆæ™‚é–“ (ç§’)',
                    streaming: 'ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°'
                };
                return labels[key] || key;
            }
            
            showStatus(message, type) {
                const statusDiv = document.getElementById('status');
                statusDiv.innerHTML = `<div class="status ${type}">${message}</div>`;
                
                // æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯3ç§’å¾Œã«è‡ªå‹•ã§æ¶ˆã™
                if (type === 'success') {
                    setTimeout(() => {
                        statusDiv.innerHTML = '';
                    }, 3000);
                }
            }
            
            setLoading(loading) {
                const loadingDiv = document.getElementById('loading');
                const generateBtn = document.getElementById('generateBtn');
                const streamBtn = document.getElementById('streamBtn');
                
                if (loading) {
                    loadingDiv.style.display = 'block';
                    generateBtn.disabled = true;
                    streamBtn.disabled = true;
                } else {
                    loadingDiv.style.display = 'none';
                    generateBtn.disabled = false;
                    streamBtn.disabled = false;
                }
            }
            
            clearResults() {
                document.getElementById('result').value = '';
                document.getElementById('metadata').style.display = 'none';
                document.getElementById('status').innerHTML = '';
            }
        }
        
        // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
        document.addEventListener('DOMContentLoaded', () => {
            new TextGeneratorClient();
        });
    </script>
</body>
</html>
```

## âœ… æ¤œè¨¼æ–¹æ³•

### 1. ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®æ¤œè¨¼

```bash
# CloudFormationã‚¹ã‚¿ãƒƒã‚¯ã®ç¢ºèª
aws cloudformation describe-stacks \
    --stack-name ai-textgen-dev-infrastructure \
    --query 'Stacks[0].StackStatus'

# Lambdaé–¢æ•°ã®ç¢ºèª
aws lambda list-functions \
    --query 'Functions[?starts_with(FunctionName, `AI-TextGen-dev`)].FunctionName'

# API Gatewayã®ç¢ºèª
aws apigateway get-rest-apis \
    --query 'items[?name==`AI-TextGen-dev-API`].[id,name]'
```

### 2. API ãƒ†ã‚¹ãƒˆ

```bash
# åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
curl -X POST https://your-api-url/dev/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "AWSã®ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„",
    "type": "general",
    "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
    "parameters": {
      "max_tokens": 500,
      "temperature": 0.7
    }
  }'

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
curl -X POST https://your-api-url/dev/stream \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "çŸ­ã„ç‰©èªã‚’æ›¸ã„ã¦ãã ã•ã„",
    "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
    "stream": true,
    "parameters": {
      "max_tokens": 800,
      "temperature": 0.8
    }
  }'
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```python
# performance_test.py
import asyncio
import aiohttp
import time
import statistics

async def test_concurrent_requests(api_url: str, num_requests: int = 10):
    """
    åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    """
    async def make_request(session, request_id):
        payload = {
            "prompt": f"Test request {request_id}",
            "type": "general",
            "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
            "parameters": {"max_tokens": 100}
        }
        
        start_time = time.time()
        async with session.post(f"{api_url}/generate", json=payload) as response:
            result = await response.json()
            end_time = time.time()
            return end_time - start_time
    
    async with aiohttp.ClientSession() as session:
        tasks = [make_request(session, i) for i in range(num_requests)]
        response_times = await asyncio.gather(*tasks)
    
    print(f"Concurrent requests: {num_requests}")
    print(f"Average response time: {statistics.mean(response_times):.2f}s")
    print(f"Min response time: {min(response_times):.2f}s")
    print(f"Max response time: {max(response_times):.2f}s")
    print(f"Median response time: {statistics.median(response_times):.2f}s")

if __name__ == "__main__":
    api_url = "https://your-api-url/dev"
    asyncio.run(test_concurrent_requests(api_url, 5))
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

#### 1. Bedrockãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `ValidationException: The provided model identifier is invalid`

**è§£æ±ºç­–**:
```bash
# ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹çŠ¶æ³ã®ç¢ºèª
aws bedrock list-foundation-models \
    --region us-east-1 \
    --query 'modelSummaries[?modelLifecycle.status==`ACTIVE`].[modelId,modelName]'

# Bedrockã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç”³è«‹
# https://console.aws.amazon.com/bedrock/home#/model-access
```

#### 2. Lambda ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `Task timed out after 30.00 seconds`

**è§£æ±ºç­–**:
```yaml
# CloudFormationã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·
Properties:
  Timeout: 300  # 5åˆ†ã«å»¶é•·
  MemorySize: 1024  # ãƒ¡ãƒ¢ãƒªã‚‚å¢—é‡
```

#### 3. APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ã®CORSã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: ãƒ–ãƒ©ã‚¦ã‚¶ã§ `CORS policy` ã‚¨ãƒ©ãƒ¼

**è§£æ±ºç­–**:
```yaml
# OPTIONSãƒ¡ã‚½ãƒƒãƒ‰ã®è¿½åŠ ã¨CORSãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®š
MethodResponses:
  - StatusCode: 200
    ResponseHeaders:
      Access-Control-Allow-Origin: true
      Access-Control-Allow-Methods: true
      Access-Control-Allow-Headers: true
```

#### 4. æ–™é‡‘ãŒäºˆæƒ³ä»¥ä¸Šã«ç™ºç”Ÿ
**ç—‡çŠ¶**: äºˆæœŸã—ãªã„é«˜é¡ãªè«‹æ±‚

**è§£æ±ºç­–**:
```python
# ã‚³ã‚¹ãƒˆç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨­å®š
def estimate_cost(input_tokens, output_tokens, model_id):
    """æ–™é‡‘ã®æ¦‚ç®—è¨ˆç®—"""
    pricing = {
        'anthropic.claude-3-haiku-20240307-v1:0': {
            'input': 0.00025,   # per 1K tokens
            'output': 0.00125
        },
        'anthropic.claude-3-sonnet-20240229-v1:0': {
            'input': 0.003,
            'output': 0.015
        }
    }
    
    if model_id in pricing:
        cost = (input_tokens/1000 * pricing[model_id]['input'] + 
                output_tokens/1000 * pricing[model_id]['output'])
        return cost
    return 0
```

### ãƒ‡ãƒãƒƒã‚°æ‰‹æ³•

#### 1. CloudWatch Logs ã®æ´»ç”¨
```python
# Lambdaé–¢æ•°ã§ã®ãƒ­ã‚°å‡ºåŠ›
import logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    logger.info(f"Received event: {json.dumps(event)}")
    # å‡¦ç†...
    logger.info(f"Response: {json.dumps(response)}")
```

#### 2. X-Ray ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
```yaml
# CloudFormationã§X-Rayã‚’æœ‰åŠ¹åŒ–
Properties:
  TracingConfig:
    Mode: Active
```

## ğŸ“Š ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

### æœˆé–“ã‚³ã‚¹ãƒˆï¼ˆé–‹ç™ºç’°å¢ƒã§ã®æƒ³å®šä½¿ç”¨é‡ï¼‰

| ã‚µãƒ¼ãƒ“ã‚¹ | ä½¿ç”¨é‡ | å˜ä¾¡ | æœˆé–“ã‚³ã‚¹ãƒˆ |
|---------|--------|------|-----------|
| Bedrock Claude 3 Haiku | 1Må…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | $0.25/1M | $0.25 |
| Bedrock Claude 3 Haiku | 1Må‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | $1.25/1M | $1.25 |
| Lambda (128MB) | 100,000å®Ÿè¡Œ | $0.20/1M | $0.02 |
| API Gateway | 100,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ | $3.50/1M | $0.35 |
| S3 Standard | 1GB | $0.023/GB | $0.02 |
| CloudWatch Logs | 1GB | $0.50/GB | $0.50 |

**é–‹ç™ºç’°å¢ƒæœˆé¡ç·è¨ˆ: ç´„ $2.39**

### æœ¬ç•ªç’°å¢ƒï¼ˆä¸­è¦æ¨¡ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ³å®šï¼‰

| ã‚µãƒ¼ãƒ“ã‚¹ | ä½¿ç”¨é‡ | å˜ä¾¡ | æœˆé–“ã‚³ã‚¹ãƒˆ |
|---------|--------|------|-----------|
| Bedrock Claude 3 Sonnet | 10Må…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | $3.00/1M | $30.00 |
| Bedrock Claude 3 Sonnet | 5Må‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | $15.00/1M | $75.00 |
| Lambda (512MB) | 1,000,000å®Ÿè¡Œ | $8.33/1M | $8.33 |
| API Gateway | 1,000,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ | $3.50/1M | $3.50 |
| S3 Standard | 10GB | $0.023/GB | $0.23 |
| CloudWatch | 10GB | $0.50/GB | $5.00 |

**æœ¬ç•ªç’°å¢ƒæœˆé¡ç·è¨ˆ: ç´„ $122.06**

## ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šé™¤æ‰‹é †

```bash
#!/bin/bash
# scripts/cleanup.sh

PROJECT_NAME="AI-TextGen"
ENVIRONMENT="dev"
REGION="us-east-1"

echo "Cleaning up ${PROJECT_NAME}-${ENVIRONMENT} resources..."

# CloudFormationã‚¹ã‚¿ãƒƒã‚¯ã®å‰Šé™¤ï¼ˆé€†é †ï¼‰
aws cloudformation delete-stack \
    --stack-name "${PROJECT_NAME}-${ENVIRONMENT}-api-gateway" \
    --region ${REGION}

aws cloudformation delete-stack \
    --stack-name "${PROJECT_NAME}-${ENVIRONMENT}-lambda-functions" \
    --region ${REGION}

aws cloudformation delete-stack \
    --stack-name "${PROJECT_NAME}-${ENVIRONMENT}-infrastructure" \
    --region ${REGION}

# S3ãƒã‚±ãƒƒãƒˆã®ä¸­èº«ã‚’å‰Šé™¤
BUCKET_NAME="${PROJECT_NAME}-${ENVIRONMENT}-prompt-templates"
aws s3 rm "s3://${BUCKET_NAME}" --recursive --region ${REGION}

# CloudWatch Log Groupsã®å‰Šé™¤
aws logs delete-log-group \
    --log-group-name "/aws/lambda/${PROJECT_NAME}-${ENVIRONMENT}-text-generator" \
    --region ${REGION}

aws logs delete-log-group \
    --log-group-name "/aws/lambda/${PROJECT_NAME}-${ENVIRONMENT}-streaming-text-generator" \
    --region ${REGION}

aws logs delete-log-group \
    --log-group-name "/aws/lambda/${PROJECT_NAME}-${ENVIRONMENT}-document-processor" \
    --region ${REGION}

echo "Cleanup completed!"
```

## ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®é«˜åº¦ãªæ©Ÿèƒ½ã«é€²ã‚€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ï¼š

### æ¨å¥¨ã•ã‚Œã‚‹å­¦ç¿’ãƒ‘ã‚¹
1. **5.2.1 ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½œæˆ**: å¯¾è©±å‹AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰
2. **5.2.2 RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ãŸè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ 
3. **5.2.3 ç”»åƒç”Ÿæˆæ©Ÿèƒ½**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIæ©Ÿèƒ½ã®å®Ÿè£…

### ç™ºå±•çš„ãªæ©Ÿèƒ½å®Ÿè£…
1. **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
2. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½**: Function Callingã‚’æ´»ç”¨ã—ãŸè‡ªå‹•åŒ–
3. **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ**: ãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒãƒ»éŸ³å£°ã®çµ±åˆå‡¦ç†
4. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å”èª¿ç·¨é›†**: è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã®åŒæ™‚ç·¨é›†æ©Ÿèƒ½

## ğŸ”— å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### AWSå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/)
- [Bedrock Runtime API Reference](https://docs.aws.amazon.com/bedrock-runtime/latest/APIReference/)
- [Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/)

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- [Anthropic Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [OpenAI Best Practices for Prompt Engineering](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

### ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¨ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—
- [Amazon Bedrock Samples](https://github.com/aws-samples/amazon-bedrock-samples)
- [Generative AI Use Cases](https://github.com/aws-samples/generative-ai-use-cases-jp)
- [AWS Bedrock Workshop](https://github.com/aws-samples/amazon-bedrock-workshop)